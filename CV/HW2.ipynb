{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# read the image file & output_image the color & gray image\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    # opencv read image in \"BGR\" color space\n",
    "    img = cv2.imread(path)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img_gray, img_rgb\n",
    "\n",
    "# the dtype of img must be \"uint8\" to avoid the error of SIFT detector\n",
    "\n",
    "\n",
    "def img_to_gray(img):\n",
    "    if img.dtype != \"uint8\":\n",
    "        print(\"The input image dtype is not uint8 , image type is : \", img.dtype)\n",
    "        return\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray\n",
    "\n",
    "\n",
    "def SIFT(img):\n",
    "    SIFT_detector = cv2.SIFT_create()\n",
    "    kp, des = SIFT_detector.detectAndCompute(img, None)\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def plot_sift(gray, rgb, kp):\n",
    "    tmp = rgb.copy()  # deep copy\n",
    "    img = cv2.drawKeypoints(\n",
    "        gray, kp, tmp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def K_NN(kp1, des1, kp2, des2, k):\n",
    "    k_nearest_neighbor = np.zeros((len(kp1), k), dtype=np.uint16)\n",
    "    for i in range(len(kp1)):\n",
    "        distance = np.zeros(len(kp2))\n",
    "        source_feature = des1[i]\n",
    "        for j in range(len(kp2)):\n",
    "            target_feature = des2[j]\n",
    "            distance[j] = np.linalg.norm(source_feature - target_feature)\n",
    "        minimum_distance_index = np.argsort(distance)\n",
    "        k_nearest_neighbor[i] = minimum_distance_index[:k]\n",
    "    return k_nearest_neighbor\n",
    "\n",
    "\n",
    "def Ratio_Test(kp1, des1, kp2, des2, nearest_neighbor, threshold):\n",
    "    matches = []\n",
    "    for i in range(len(kp1)):\n",
    "        d1 = np.linalg.norm(des1[0] - des2[nearest_neighbor[i][0]])\n",
    "        d2 = np.linalg.norm(des1[0] - des2[nearest_neighbor[i][1]])\n",
    "        if d1 < threshold * d2:\n",
    "            matches.append(list(kp1[i].pt + kp2[nearest_neighbor[i][0]].pt))\n",
    "    matches = np.array(matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    def plot_matches(matches, concatenate_image):\n",
    "        match_img = concatenate_image.copy()\n",
    "        offset = concatenate_image.shape[1]/2\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(np.array(match_img).astype('uint8'),\n",
    "                cmap=\"gray\")  # 　RGB is integer type\n",
    "\n",
    "        ax.plot(matches[:, 0], matches[:, 1], 'xr')\n",
    "        ax.plot(matches[:, 2] + offset, matches[:, 3], 'xr')\n",
    "\n",
    "        ax.plot([matches[:, 0], matches[:, 2] + offset], [matches[:, 1], matches[:, 3]],\n",
    "                'r', linewidth=0.5)\n",
    "\n",
    "        plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    # p2 = Hp1\n",
    "    # (wx2, wy2 , w) = H(x1, y1, 1)\n",
    "    # H = [\n",
    "    #      [A11, A12, A13],\n",
    "    #      [A21, A22, A23],\n",
    "    #      [A31, A32, A33]\n",
    "    #     ]\n",
    "    # w = x1A31 + y1A32 + A33\n",
    "    # wx2 = x2(x1A31 + y1A32 + A33) = x1A11 + y1A12 + A13\n",
    "        # >> x1A11 + y1A12 + A13 - x2(x1A31 + y1A32 + A33) = 0\n",
    "    # wy2 = y2(x1A31 + y1A32 + A33) = x1A21 + y1A22 + A23\n",
    "        # >> x1A21 + y1A22 + A23 - y2(x1A31 + y1A32 + A33) = 0\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def homography(samples):\n",
    "    a_matrix = []\n",
    "    for sample in samples:\n",
    "        p1 = np.append(sample[:2], 1)  # x1, y1, 1\n",
    "        p2 = np.append(sample[2:], 1)  # x2, y2, 1\n",
    "        a1 = [p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1], -p2[0]]\n",
    "        a2 = [0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1], -p2[1]]\n",
    "        a_matrix.append(a1)\n",
    "        a_matrix.append(a2)\n",
    "    a_matrix = np.array(a_matrix)\n",
    "    # corresponding smallest eigenvalue of eigenvector\n",
    "    _, _, vh = np.linalg.svd(a_matrix)\n",
    "    h = vh[-1].reshape(3, 3)\n",
    "    h = h / h[2][2]\n",
    "    return h\n",
    "\n",
    "\n",
    "def Ransac(matches, threshold, iterations):\n",
    "    best_h_matrix = []\n",
    "    best_inliers = []\n",
    "    for iter in range(iterations):\n",
    "        samples_index = random.sample(range(len(matches)), 4)\n",
    "        samples = [matches[index] for index in samples_index]\n",
    "        h_matrix = homography(samples)\n",
    "        all_p1 = np.concatenate(\n",
    "            (matches[:, :2], np.ones((len(matches), 1))), axis=1)\n",
    "        all_p2 = matches[:, 2:]\n",
    "        estimate_p2 = np.matmul(h_matrix, all_p1.T).T\n",
    "        # print(estimate_p2.shape)\n",
    "        for i in range(len(matches)):\n",
    "            estimate_p2[i] = estimate_p2[i] / estimate_p2[i][2]\n",
    "        estimate_p2 = estimate_p2[:, 0:2]\n",
    "        errors = np.linalg.norm(all_p2 - estimate_p2, axis=1)**2\n",
    "        inliers_index = np.where(errors < threshold)[0]\n",
    "        inliers = matches[inliers_index]\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_h_matrix = h_matrix\n",
    "    return best_inliers, best_h_matrix\n",
    "\n",
    "\n",
    "def translate(image1, image2, h_matrix):\n",
    "    h1, w1, c1 = image1.shape\n",
    "    h2, w2, c2 = image2.shape\n",
    "    # 以image2中的四個corner的座標當作基準去計算\n",
    "    corners = np.array(\n",
    "        [[0, 0, 1], [w2 - 1, 0, 1], [w2 - 1, h2 - 1, 1], [0, h2 - 1, 1]])\n",
    "    # 把image2四個corner的座標經過homography matrix轉換後\n",
    "    # 得到在image1相對應的座標\n",
    "    transform_corners = np.matmul(h_matrix, corners.T).T\n",
    "    for i in range(len(corners)):\n",
    "        transform_corners[i] = transform_corners[i] / transform_corners[i][2]\n",
    "\n",
    "    transform_corners = transform_corners[:, :2]\n",
    "    x_min = min(min(transform_corners[:, 0]), 0)\n",
    "    y_min = min(min(transform_corners[:, 1]), 0)\n",
    "    \"\"\"\n",
    "    print(transform_corners) \n",
    "                            [[-170.06491952  -49.23902745] image2中(0, 0)對應到image1的座標\n",
    "                            [ 836.57361736   38.94680412]  image2中(w2 - 1, 0)對應到image1的座標\n",
    "                            [ 820.07621228  745.49125985]    ''    (w2 - 1, h2 - 1)    ''\n",
    "                            [-205.34991699  763.95041104]]   ''    (0, h2 - 1)    ''\n",
    "    \"\"\"\n",
    "    size = (int(round(w2 + abs(x_min))), int(round(h2 + abs(y_min))))\n",
    "\n",
    "    # h_matrix是使用image2轉換成image1\n",
    "    # 所以A是把image1轉換到與image2的translation_matrix\n",
    "    translation_matrix = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "    A = np.matmul(translation_matrix, h_matrix)\n",
    "    \"\"\"\n",
    "        print(size) >> (1213, 805)\n",
    "    \"\"\"\n",
    "    # 把image1用合併後的size來表示的話，\n",
    "    # 是對image1和translation_matrix A 做運算\n",
    "    warped_1 = cv2.warpPerspective(src=image1, M=A, dsize=size)\n",
    "\n",
    "    # 因為我們是以image2為基準，\n",
    "    # 所以要把image2以合併後的size表示的話\n",
    "    # 只需要做affine translation就好\n",
    "\n",
    "    print(h_matrix)\n",
    "    print(translation_matrix)\n",
    "    print(A)\n",
    "\n",
    "    warped_2 = cv2.warpPerspective(\n",
    "        src=image2, M=translation_matrix, dsize=size)\n",
    "    return warped_1, warped_2\n",
    "\n",
    "\n",
    "def isblack(pixel):\n",
    "    black_pixel = np.array([0, 0, 0])\n",
    "    return np.array_equal(pixel, black_pixel)\n",
    "\n",
    "\n",
    "def stitch_image(warped_1, warped_2):\n",
    "    rows, cols, channels = warped_1.shape\n",
    "    output_image = np.zeros((rows, cols, channels), dtype=np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (not isblack(warped_1[i][j])) and isblack(warped_2[i][j]):\n",
    "                output_image[i][j][:] = warped_1[i][j][:]\n",
    "            elif isblack(warped_1[i][j]) and (not isblack(warped_2[i][j])):\n",
    "                output_image[i][j][:] = warped_2[i][j][:]\n",
    "            elif (not isblack(warped_1[i][j])) and (not isblack(warped_2[i][j])):\n",
    "                output_image[i][j][:] = (\n",
    "                    warped_1[i][j][:] / 2) + (warped_2[i][j][:] / 2)\n",
    "            else:\n",
    "                pass\n",
    "    return output_image\n",
    "# create a window to show the image\n",
    "# It will show all the windows after you call im_show()\n",
    "# Remember to call im_show() in the end of main\n",
    "\n",
    "\n",
    "def create_im_window(window_name, img):\n",
    "    cv2.imshow(window_name, img)\n",
    "\n",
    "# show the all window you call before im_show()\n",
    "# and press any key to close all windows\n",
    "\n",
    "\n",
    "def im_show():\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Stitch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_gray, image1_rgb = read_img(\"test/m1.jpg\")\n",
    "image2_gray, image2_rgb = read_img(\"test/m2.jpg\")\n",
    "\"\"\"\n",
    "    # concat_rgb = np.concatenate([image1_rgb, image2_rgb], axis=1)\n",
    "    # concat_gray = np.concatenate([image1_gray, image2_gray], axis=1)\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(concat_rgb)\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.imshow(concat_gray, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "\"\"\"\n",
    "kp1, des1 = SIFT(image1_gray)\n",
    "kp2, des2 = SIFT(image2_gray)\n",
    "\n",
    "\"\"\" Plot the keypoints in concatenate images\n",
    "    # image1_sift = plot_sift(image1_gray, image1_rgb, kp1)\n",
    "    # image2_sift = plot_sift(image2_gray, image2_rgb, kp2)\n",
    "    # concat_SIFT = np.concatenate([image1_sift, image2_sift], axis=1)\n",
    "    # plt.imshow(concat_SIFT)\n",
    "\"\"\"\n",
    "# Show the coordinate of keypoint\n",
    "# keypoints are in the form of x-y coordinate, not the common seen row-column form.\n",
    "# coordinate = cv2.KeyPoint_convert(kp1)\n",
    "\n",
    "two_nn = K_NN(kp1, des1, kp2, des2, 2)\n",
    "matches = Ratio_Test(kp1, des1, kp2, des2, two_nn, 0.95)\n",
    "# plot_matches(matches, concat_gray)\n",
    "\n",
    "best_inliers, best_h_matrix = Ransac(matches, 5, 2000)\n",
    "# plot_matches(best_inliers, concat_gray)\n",
    "\n",
    "warped_1, warped_2 = translate(image1_rgb, image2_rgb, best_h_matrix)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(warped_1)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(warped_2)\n",
    "output_image = stitch_image(warped_1, warped_2)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(output_image)\n",
    "plt.show()\n",
    "\n",
    "# the example of image window\n",
    "# create_im_window(\"Result\", test)\n",
    "# im_show()\n",
    "\n",
    "# you can use this function to store the result\n",
    "cv2.imwrite(\"result.jpg\", output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main stitch more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m1.jpg', 'm2.jpg', 'm3.jpg', 'm4.jpg', 'm5.jpg', 'm6.jpg', 'm7.jpg', 'm8.jpg', 'm9.jpg', 'm10.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_list = [\"m{}.jpg\".format(i+1) for i in range(10)]\n",
    "print(image_list)\n",
    "left = cv2.imread(\"test/m1.jpg\")\n",
    "left_gray = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "left_rgb = cv2.cvtColor(left, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for index in range(9):\n",
    "    left = cv2.imread(\"test/m1.jpg\")\n",
    "    left_gray = cv2.cvtColor(output_image, cv2.COLOR_BGR2GRAY)\n",
    "    left_rgb = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    right_gray, right_rgb = read_img(\"test/{}\".format(image_list[index+1]))\n",
    "    left_kp, left_des = SIFT(left_gray)\n",
    "    right_kp, right_des = SIFT(right_gray)\n",
    "\n",
    "    two_nn = K_NN(left_kp, left_des, right_kp, right_des, 2)\n",
    "    matches = Ratio_Test(left_kp, left_des, right_kp, right_des, two_nn, 0.95)\n",
    "\n",
    "    best_inliers, best_h_matrix = Ransac(matches, 5, 2000)\n",
    "\n",
    "    left_warped, right_warped = translate(left_rgb, right_rgb, best_h_matrix)\n",
    "    output_image = stitch_image(left_warped, right_warped)\n",
    "\n",
    "    left = output_image\n",
    "plt.imshow(output_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_gray, image1_rgb = read_img(\"test/m1.jpg\")\n",
    "image2_gray, image2_rgb = read_img(\"test/m2.jpg\")\n",
    "\"\"\"\n",
    "    # concat_rgb = np.concatenate([image1_rgb, image2_rgb], axis=1)\n",
    "    # concat_gray = np.concatenate([image1_gray, image2_gray], axis=1)\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(concat_rgb)\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.imshow(concat_gray, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "\"\"\"\n",
    "kp1, des1 = SIFT(image1_rgb)\n",
    "kp2, des2 = SIFT(image1_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
